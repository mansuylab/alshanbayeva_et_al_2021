---
title: "Cauda EVs miRNAs analysis using data from both runs"
author: "Anar Alshanbayeva"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: tango
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    keep_md: no
    number_sections: no
    fig_width: 8
    fig_height: 8
    fig_caption: true
    df_print: paged
    code_folding: hide
  fontsize: 12pt
  geometry: margin=1in
  documentclass: article
# bibliography: references.bib
link-citations: yes
---


```{r, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

# Libraries required for data analysis
```{r, message=FALSE, warning=FALSE}
source("src.R")
```


# Data: read counts table from both runs
```{r}
counts_total_run3 <- read.table(
  file = "run3_excerpt_counts/exceRpt_miRNA_ReadCounts.txt",
  header = TRUE, sep = "", row.names = 1
)

counts_total_run4 <- read.table(
  file = "run4_excerpt_counts_/exceRpt_miRNA_ReadCounts.txt",
  header = TRUE, sep = "", row.names = 1
)

colnames(counts_total_run4) <- paste0(colnames(counts_total_run4), "_2")

df <- merge(counts_total_run3, counts_total_run4, by = "row.names")
rownames(df) <- df$Row.names
df <- df[, -1]

knitr::kable(head(df))
```


## Specifying the group & batch while filterByExprs()
```{r}
counts_total <- df
d <- data.frame(
  row.names = colnames(counts_total),
  group = c(
    "MSUS", "CTRL", "MSUS", "CTRL", "MSUS",
    "CTRL", "MSUS", "CTRL", "CTRL", "MSUS",
    "MSUS", "CTRL", "MSUS", "CTRL", "MSUS",
    "CTRL", "MSUS", "CTRL", "CTRL", "MSUS"
  ),
  batch = c(
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2
  )
)

counts_total[is.na(counts_total)] <- 0

dds <- calcNormFactors(DGEList(counts_total), method = "TMM")

dds$samples$group <- c(
  "MSUS", "CTRL", "MSUS", "CTRL", "MSUS", "CTRL", "MSUS", "CTRL", "CTRL",
  "MSUS", "MSUS", "CTRL", "MSUS", "CTRL", "MSUS", "CTRL", "MSUS", "CTRL",
  "CTRL", "MSUS"
)

dds$samples$batch <- c(
  1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
  2, 2, 2, 2, 2, 2, 2, 2, 2, 2
)

mm <- model.matrix(~ batch + group, data = d)
mm

### specifying thebatch while filtering by expression
dds <- dds[which(filterByExpr(dds, design = mm, min.count = 20, min.prop = 0.8)), ]

# normalization by counts per million
en <- log1p(edgeR::cpm(dds))
```

## PCA plots {.tabset .tabset-pills}

### Samples colored by group and shaped by batched
```{r}
plgINS::plPCA(en,
  colorBy = dds$samples$group, add.labels = FALSE,
  points.size = 12, shapeBy = paste0("Batch", dds$samples$batch)
)
```

### Samples colored by library sizes and shaped by group
```{r}
plgINS::plPCA(en,
  colorBy = dds$samples$lib.size, add.labels = FALSE,
  points.size = 12, shapeBy = dds$samples$group
)
```

### Samples colored by library sizes and shaped by batches
```{r}
plgINS::plPCA(en,
  colorBy = dds$samples$lib.size, add.labels = FALSE,
  points.size = 12, shapeBy = dds$samples$batch
)
```



### Without RUVSeq:
```{r}
mm <- model.matrix(~ dds$samples$batch + dds$samples$group, data = d)
mm
dds <- estimateDisp(dds, mm)
fit <- glmLRT(glmFit(dds, mm), coef = "dds$samples$groupMSUS")
res_without_ruvseq <- as.data.frame(topTags(fit, Inf))
head(res_without_ruvseq, n = 20)

hist(res_without_ruvseq$PValue)
```

## With RUVSeq (Only with 1 SV)
```{r}
re <- RUVSeq::RUVs(en,
  cIdx = row.names(en), k = 1, scIdx =
    RUVSeq::makeGroups(d$group), isLog = TRUE
)
d$SV1 <- re$W[, 1]
d$SV1

mm <- model.matrix(~ d$SV1 + dds$samples$batch + dds$samples$group, data = d)
mm

dds <- estimateDisp(dds, mm)
fit <- glmLRT(glmFit(dds, mm), coef = "dds$samples$groupMSUS")
res_with_ruvseq1 <- as.data.frame(topTags(fit, Inf))
head(res_with_ruvseq1, n = 20)

hist(res_with_ruvseq1$PValue)
```


## PCA plot with 1 SV
### Samples colored by group and shaped by batched
```{r}
plgINS::plPCA(re$normalizedCounts,
  colorBy = dds$samples$group, add.labels = FALSE,
  points.size = 12, shapeBy = paste0("Batch", dds$samples$batch)
)
```

### Samples colored by library sizes and shaped by group
```{r}
plgINS::plPCA(re$normalizedCounts,
  colorBy = dds$samples$lib.size, add.labels = FALSE,
  points.size = 12, shapeBy = dds$samples$group
)
```

### Samples colored by library sizes and shaped by batches
```{r}
plgINS::plPCA(re$normalizedCounts,
  colorBy = dds$samples$lib.size, add.labels = FALSE,
  points.size = 12, shapeBy = dds$samples$batch
)
```


## With RUVSeq (Only with 2 SVs)
```{r}
re <- RUVSeq::RUVs(en,
  cIdx = row.names(en), k = 2,
  scIdx = RUVSeq::makeGroups(d$group), isLog = TRUE
)
### add the variable (suppose I have only one) to the colData dataframe:
d$SV1 <- re$W[, 1]
d$SV2 <- re$W[, 2]

mm <- model.matrix(~ d$SV1 + d$SV2 + dds$samples$group, data = d)
dds <- estimateDisp(dds, mm)
fit <- glmLRT(glmFit(dds, mm), coef = "dds$samples$groupMSUS")
res_with_ruvseq2 <- as.data.frame(topTags(fit, Inf))

res_with_ruvseq2$LR <- rownames(res_with_ruvseq2)

write_csv(res_with_ruvseq2, "./output/res_with_ruvseq2.csv")

head(res_with_ruvseq2, n = 20)
hist(res_with_ruvseq2$PValue)
```

## PCA plot with 2 SV
### Samples colored by group and shaped by batched
```{r}
plgINS::plPCA(re$normalizedCounts,
  colorBy = dds$samples$group, add.labels = FALSE,
  points.size = 12, shapeBy = paste0("Batch", dds$samples$batch)
)
```

### Samples colored by library sizes and shaped by group
```{r}
plgINS::plPCA(re$normalizedCounts,
  colorBy = dds$samples$lib.size, add.labels = FALSE,
  points.size = 12, shapeBy = dds$samples$group
)
```

### Samples colored by library sizes and shaped by batches
```{r}
plgINS::plPCA(re$normalizedCounts,
  colorBy = dds$samples$lib.size, add.labels = FALSE,
  points.size = 12, shapeBy = dds$samples$batch
)
```


## Trying Limma on the same

```{r, eval = FALSE}
metadata <- read_excel("/Users/alshanbayeva/data_analysis_september/metadata_caudaEVs.xlsx")
# apply duplicateCorrelation is two rounds
(design <- model.matrix(~ batch + group, metadata))
vobj_tmp <- voom(dds, design, plot = TRUE)
dupcor <- duplicateCorrelation(vobj_tmp, design, block = metadata$Individual)

# run voom considering the duplicateCorrelation results
# in order to compute more accurate precision weights
# Otherwise, use the results from the first voom run
vobj <- voom(dds, design,
  plot = TRUE, block = metadata$Individual,
  correlation = dupcor$consensus.correlation
)

# Estimate linear mixed model with a single variance component
# Fit the model for each gene,
dupcor <- duplicateCorrelation(vobj, design, block = metadata$Individual) # here the original vobj_tmp was used instead of vobj

# But this step uses only the genome-wide average for the random effect
fitDupCor <- lmFit(vobj, design, block = metadata$Individual, correlation = dupcor$consensus.correlation)

# Fit Empirical Bayes for moderated t-statistics
fitDupCor <- eBayes(fitDupCor)
dealimma <- topTable(fitDupCor, number = 50)
dealimma

dealimma$P.Value <- rownames(dealimma)
write_csv(dealimma, path = "/Users/alshanbayeva/Desktop/caudaEVs_story_manuscript/deepak/raw_data_excerpt/the_final_code_for_submission/dealimma_2runs_miRNAsonly.csv")
# EnhancedVolcano(dealimma,  lab = rownames(dealimma),  x = 'F',  y = 'adj.P.Val')
```

# References
```{r}
report::cite_packages(sessionInfo())
```


# SessionInfo
```{r}
devtools::session_info() %>%
  details::details()
```
